{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "52c3e8a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# Load reduced dataset\n",
    "df = pd.read_csv(\"../data/heart_disease_selected_features.csv\")\n",
    "\n",
    "# Separate features and target\n",
    "X = df.drop(columns=[\"num\"])  # or \"target\"\n",
    "y = (df[\"num\"] > 0).astype(int)  # convert to binary\n",
    "\n",
    "# Train/Test Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e370297f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Logistic Regression params: {'C': 0.1, 'penalty': 'l1', 'solver': 'liblinear'}\n"
     ]
    }
   ],
   "source": [
    "param_grid_lr = {\n",
    "    \"C\": [0.01, 0.1, 1, 10],\n",
    "    \"penalty\": [\"l1\", \"l2\"],\n",
    "    \"solver\": [\"liblinear\"]\n",
    "}\n",
    "\n",
    "grid_lr = GridSearchCV(LogisticRegression(max_iter=2000), param_grid_lr, cv=5, scoring=\"f1\")\n",
    "grid_lr.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best Logistic Regression params:\", grid_lr.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "07c16a4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Decision Tree params: {'criterion': 'gini', 'max_depth': 5, 'min_samples_split': 10}\n"
     ]
    }
   ],
   "source": [
    "param_grid_dt = {\n",
    "    \"max_depth\": [3, 5, 10, None],\n",
    "    \"min_samples_split\": [2, 5, 10],\n",
    "    \"criterion\": [\"gini\", \"entropy\"]\n",
    "}\n",
    "\n",
    "grid_dt = GridSearchCV(DecisionTreeClassifier(random_state=42), param_grid_dt, cv=5, scoring=\"f1\")\n",
    "grid_dt.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best Decision Tree params:\", grid_dt.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "23ae5095",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Random Forest params: {'n_estimators': 200, 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_depth': None, 'bootstrap': False}\n"
     ]
    }
   ],
   "source": [
    "param_dist_rf = {\n",
    "    \"n_estimators\": [100, 200, 300, 500],\n",
    "    \"max_depth\": [None, 5, 10, 20],\n",
    "    \"min_samples_split\": [2, 5, 10],\n",
    "    \"min_samples_leaf\": [1, 2, 4],\n",
    "    \"bootstrap\": [True, False]\n",
    "}\n",
    "\n",
    "random_rf = RandomizedSearchCV(\n",
    "    RandomForestClassifier(random_state=42),\n",
    "    param_distributions=param_dist_rf,\n",
    "    n_iter=20, cv=5, scoring=\"f1\", random_state=42, n_jobs=-1\n",
    ")\n",
    "random_rf.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best Random Forest params:\", random_rf.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ab06ad11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best SVM params: {'C': 1, 'gamma': 'scale', 'kernel': 'linear'}\n"
     ]
    }
   ],
   "source": [
    "param_grid_svm = {\n",
    "    \"C\": [0.1, 1, 10],\n",
    "    \"kernel\": [\"linear\", \"rbf\"],\n",
    "    \"gamma\": [\"scale\", \"auto\"]\n",
    "}\n",
    "\n",
    "grid_svm = GridSearchCV(SVC(probability=True), param_grid_svm, cv=5, scoring=\"f1\")\n",
    "grid_svm.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best SVM params:\", grid_svm.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e97bf43f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Logistic Regression</th>\n",
       "      <td>0.836066</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.827586</td>\n",
       "      <td>0.926407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision Tree</th>\n",
       "      <td>0.754098</td>\n",
       "      <td>0.696970</td>\n",
       "      <td>0.821429</td>\n",
       "      <td>0.754098</td>\n",
       "      <td>0.851190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest</th>\n",
       "      <td>0.901639</td>\n",
       "      <td>0.843750</td>\n",
       "      <td>0.964286</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.957792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM</th>\n",
       "      <td>0.852459</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.892857</td>\n",
       "      <td>0.847458</td>\n",
       "      <td>0.942641</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Accuracy  Precision    Recall        F1       AUC\n",
       "Logistic Regression  0.836066   0.800000  0.857143  0.827586  0.926407\n",
       "Decision Tree        0.754098   0.696970  0.821429  0.754098  0.851190\n",
       "Random Forest        0.901639   0.843750  0.964286  0.900000  0.957792\n",
       "SVM                  0.852459   0.806452  0.892857  0.847458  0.942641"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_models = {\n",
    "    \"Logistic Regression\": grid_lr.best_estimator_,\n",
    "    \"Decision Tree\": grid_dt.best_estimator_,\n",
    "    \"Random Forest\": random_rf.best_estimator_,\n",
    "    \"SVM\": grid_svm.best_estimator_\n",
    "}\n",
    "\n",
    "results = {}\n",
    "for name, model in best_models.items():\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_prob = model.predict_proba(X_test)[:, 1] if hasattr(model, \"predict_proba\") else None\n",
    "    \n",
    "    results[name] = {\n",
    "        \"Accuracy\": accuracy_score(y_test, y_pred),\n",
    "        \"Precision\": precision_score(y_test, y_pred),\n",
    "        \"Recall\": recall_score(y_test, y_pred),\n",
    "        \"F1\": f1_score(y_test, y_pred),\n",
    "        \"AUC\": roc_auc_score(y_test, y_prob) if y_prob is not None else None\n",
    "    }\n",
    "\n",
    "pd.DataFrame(results).T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "45dc7237",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved best model (Random Forest) → ../models/final_model.pkl\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "import os\n",
    "\n",
    "os.makedirs(\"../models\", exist_ok=True)\n",
    "\n",
    "# Pick the best model (highest F1 or AUC)\n",
    "best_model_name = max(results, key=lambda x: results[x][\"F1\"])\n",
    "best_model = best_models[best_model_name]\n",
    "\n",
    "joblib.dump(best_model, f\"../models/final_model.pkl\")\n",
    "print(f\"Saved best model ({best_model_name}) → ../models/final_model.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "47faafa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved evaluation metrics → ../results/evaluation_metrics.txt\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Ensure results directory exists\n",
    "os.makedirs(\"../results\", exist_ok=True)\n",
    "\n",
    "# Save evaluation metrics\n",
    "with open(\"../results/evaluation_metrics.txt\", \"w\") as f:\n",
    "    f.write(\"Model Evaluation Metrics\\n\")\n",
    "    f.write(\"========================\\n\\n\")\n",
    "    for model, metrics in results.items():\n",
    "        f.write(f\"{model}:\\n\")\n",
    "        for metric, value in metrics.items():\n",
    "            f.write(f\"  {metric}: {value:.4f}\\n\")\n",
    "        f.write(\"\\n\")\n",
    "\n",
    "print(\"Saved evaluation metrics → ../results/evaluation_metrics.txt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e44ce05",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
